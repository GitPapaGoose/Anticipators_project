{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7425e791",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/opt/miniconda3/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <636BF463-1886-392D-B8B3-6011C44DCEE9> /opt/miniconda3/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/miniconda3/lib/python3.13/lib-dynload/../../libomp.dylib' (no such file), '/opt/miniconda3/bin/../lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/xgboost/core.py:308\u001b[39m\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m    314\u001b[39m \u001b[33;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m        return value from API calls\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/xgboost/core.py:270\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[32m    269\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    271\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    279\u001b[39m \n\u001b[32m    280\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    281\u001b[39m \n\u001b[32m    282\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    284\u001b[39m         )\n\u001b[32m    285\u001b[39m     _register_log_callback(lib)\n\u001b[32m    287\u001b[39m     libver = _lib_version(lib)\n",
      "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/opt/miniconda3/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <636BF463-1886-392D-B8B3-6011C44DCEE9> /opt/miniconda3/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/miniconda3/lib/python3.13/lib-dynload/../../libomp.dylib' (no such file), '/opt/miniconda3/bin/../lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Загрузка данных ===\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Сохраняем ID для submission\n",
    "train_id = train['Id']\n",
    "test_id = test['Id']\n",
    "\n",
    "# Удаляем Id (не нужен для обучения)\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "# === Целевая переменная: логарифм SalePrice ===\n",
    "y = np.log1p(train['SalePrice'])\n",
    "train.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "# === Объединение данных для единообразной обработки ===\n",
    "n_train = len(train)\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# === Фичи: добавим инженерные признаки ===\n",
    "\n",
    "# Площадь\n",
    "data['TotalSF'] = data['GrLivArea'] + data['TotalBsmtSF'] + data['GarageArea'] + data['WoodDeckSF'] + data['OpenPorchSF']\n",
    "data['TotalBath'] = data['FullBath'] + data['HalfBath'] + data['BsmtFullBath'] + data['BsmtHalfBath']\n",
    "data['TotalPorchSF'] = data['OpenPorchSF'] + data['EnclosedPorch'] + data['3SsnPorch'] + data['ScreenPorch']\n",
    "data['TotalRoom'] = data['TotRmsAbvGrd'] + data['BedroomAbvGr'] + data['KitchenAbvGr']\n",
    "\n",
    "# Возраст\n",
    "current_year = 2025  # важно: актуальный год!\n",
    "data['Age'] = current_year - data['YearBuilt']\n",
    "data['RemodAge'] = current_year - data['YearRemodAdd']\n",
    "data['AgeSinceRemodel'] = data['Age'] - data['RemodAge']\n",
    "data['AgeSinceRemodel'].fillna(0, inplace=True)\n",
    "\n",
    "# Признаки наличия\n",
    "data['HasGarage'] = (data['GarageCars'] > 0).astype(int)\n",
    "data['HasBasement'] = (data['TotalBsmtSF'] > 0).astype(int)\n",
    "data['HasFireplace'] = (data['Fireplaces'] > 0).astype(int)\n",
    "data['HasPool'] = (data['PoolArea'] > 0).astype(int)\n",
    "data['HasFence'] = (data['Fence'] != 'None').astype(int)\n",
    "data['HasAlley'] = (data['Alley'] != 'None').astype(int)\n",
    "data['HasWoodDeck'] = (data['WoodDeckSF'] > 0).astype(int)\n",
    "data['Has3SsnPorch'] = (data['3SsnPorch'] > 0).astype(int)\n",
    "data['HasOpenPorch'] = (data['OpenPorchSF'] > 0).astype(int)\n",
    "\n",
    "# Отношения площадей\n",
    "data['LivingAreaRatio'] = data['GrLivArea'] / data['LotArea']\n",
    "data['BasementToTotalSF'] = data['TotalBsmtSF'] / data['TotalSF']\n",
    "data['GarageToTotalSF'] = data['GarageArea'] / data['TotalSF']\n",
    "\n",
    "# Качество и состояние\n",
    "data['OverallQuality'] = data['OverallQual']\n",
    "data['OverallCondition'] = data['OverallCond']\n",
    "data['QualCond'] = data['OverallQuality'] * data['OverallCondition']\n",
    "\n",
    "# Категориальные признаки: замена NA\n",
    "categorical_cols = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                    'Electrical', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                    'PoolQC', 'Fence', 'MiscFeature', 'MasVnrType']\n",
    "for col in categorical_cols:\n",
    "    data[col].fillna('None', inplace=True)\n",
    "\n",
    "# Преобразование категориальных признаков в числовые\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# One-Hot Encoding для некоторых категорий\n",
    "data = pd.get_dummies(data, columns=['Neighborhood', 'MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n",
    "                                      'LotConfig', 'LandSlope', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',\n",
    "                                      'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'CentralAir',\n",
    "                                      'Electrical', 'Functional', 'GarageType', 'PavedDrive', 'SaleType', 'SaleCondition'])\n",
    "\n",
    "# Пропуски в числовых признаках — заполнение медианой\n",
    "num_cols = data.select_dtypes(include=[np.number]).columns\n",
    "data[num_cols] = data[num_cols].fillna(data[num_cols].median())\n",
    "\n",
    "# Нормализация (RobustScaler лучше, так как устойчив к выбросам)\n",
    "scaler = RobustScaler()\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "# Разделение обратно на train и test\n",
    "X_train = data[:n_train]\n",
    "X_test = data[n_train:]\n",
    "\n",
    "# === Стекинг (Stacking) ===\n",
    "# Модели на первом уровне\n",
    "base_models = [\n",
    "    ('xgb', XGBRegressor(random_state=42, n_estimators=1000, max_depth=6, learning_rate=0.01)),\n",
    "    ('lgbm', LGBMRegressor(random_state=42, n_estimators=1000, max_depth=6, learning_rate=0.01)),\n",
    "    ('catb', CatBoostRegressor(silent=True, random_state=42, n_estimators=1000, depth=6))\n",
    "]\n",
    "\n",
    "# Второй уровень модель (регрессор, который обучается на прогнозах базовых моделей)\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Создаем стекинг\n",
    "class StackingRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, base_models, meta_model):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Обучаем базовые модели\n",
    "        for name, model in self.base_models:\n",
    "            model.fit(X, y)\n",
    "            self.models.append((name, model))\n",
    "\n",
    "        # Предсказания базовых моделей на тренировочных данных\n",
    "        predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, (name, model) in enumerate(self.models):\n",
    "            predictions[:, i] = model.predict(X)\n",
    "\n",
    "        # Обучаем мета-модель\n",
    "        self.meta_model.fit(predictions, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Предсказания базовых моделей\n",
    "        predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, (name, model) in enumerate(self.models):\n",
    "            predictions[:, i] = model.predict(X)\n",
    "\n",
    "        # Предсказание мета-модели\n",
    "        return self.meta_model.predict(predictions)\n",
    "\n",
    "# === Обучение и оценка ===\n",
    "stacker = StackingRegressor(base_models=base_models, meta_model=meta_model)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(stacker, X_train, y, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-cv_scores)\n",
    "print(f\"CV RMSE: {rmse_scores.mean():.4f} (+/- {rmse_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Обучаем на всей выборке\n",
    "stacker.fit(X_train, y)\n",
    "\n",
    "# Предсказание на тесте\n",
    "preds = stacker.predict(X_test)\n",
    "preds = np.expm1(preds)  # обратное преобразование от log\n",
    "\n",
    "# === Сабмит ===\n",
    "submission = pd.DataFrame({'Id': test_id, 'SalePrice': preds})\n",
    "submission.to_csv('submission_stacking.csv', index=False)\n",
    "print(\"Submission saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Загрузка данных ===\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Сохраняем ID\n",
    "train_id = train['Id']\n",
    "test_id = test['Id']\n",
    "\n",
    "# Удаляем Id\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "# === Целевая переменная: логарифм SalePrice ===\n",
    "y = np.log1p(train['SalePrice'])\n",
    "train.drop('SalePrice', axis=1, inplace=True)\n",
    "\n",
    "# === Объединение данных ===\n",
    "n_train = len(train)\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# === Инженерия признаков (пример) ===\n",
    "# (заменить на твой код, если нужно)\n",
    "\n",
    "# Пример: добавление новых фичей\n",
    "data['TotalSF'] = data['GrLivArea'] + data['TotalBsmtSF'] + data['GarageArea']\n",
    "data['Age'] = 2025 - data['YearBuilt']\n",
    "data['HasGarage'] = (data['GarageCars'] > 0).astype(int)\n",
    "data['HasBasement'] = (data['TotalBsmtSF'] > 0).astype(int)\n",
    "\n",
    "# Категориальные признаки\n",
    "categorical_cols = ['Alley', 'BsmtQual', 'BsmtCond', 'FireplaceQu', 'GarageType', 'PoolQC']\n",
    "for col in categorical_cols:\n",
    "    data[col].fillna('None', inplace=True)\n",
    "\n",
    "# OneHotEncoding\n",
    "one_hot_coder = ['Neighborhood', 'MSZoning', 'Street', 'LotShape', 'BldgType']\n",
    "target_coder = ['Exterior1st', 'Exterior2nd', 'KitchenQual', 'Functional']\n",
    "\n",
    "# Преобразование категориальных\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Создание preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('ohe', OneHotEncoder(sparse_output=False), one_hot_coder),\n",
    "        ('target', TargetEncoder(), target_coder),\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# === Функция для оценки модели ===\n",
    "def objective(trial):\n",
    "    # Гиперпараметры для CatBoost\n",
    "    cat_params = {\n",
    "        'iterations': trial.suggest_int('cat_iterations', 200, 800),\n",
    "        'learning_rate': trial.suggest_float('cat_learning_rate', 1e-3, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('cat_depth', 4, 10),\n",
    "        'random_state': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    # LGBM\n",
    "    lgbm_params = {\n",
    "        'n_estimators': trial.suggest_int('lgbm_n_estimators', 200, 600),\n",
    "        'max_depth': trial.suggest_int('lgbm_max_depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('lgbm_learning_rate', 1e-3, 0.1, log=True),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # RF\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 200, 600),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 4, 10),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # Ridge (мета-модель)\n",
    "    ridge_alpha = trial.suggest_float('ridge_alpha', 0.1, 10.0)\n",
    "\n",
    "    # Создание базовых моделей\n",
    "    base_models = [\n",
    "        ('catboost', CatBoostRegressor(**cat_params)),\n",
    "        ('lgbm', LGBMRegressor(**lgbm_params)),\n",
    "        ('rf', RandomForestRegressor(**rf_params))\n",
    "    ]\n",
    "\n",
    "    # Мета-модель\n",
    "    meta_model = Ridge(alpha=ridge_alpha)\n",
    "\n",
    "    # Стекинг\n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=meta_model,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    )\n",
    "\n",
    "    # Пайплайн\n",
    "    ml_stack_pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('stack', stacking_regressor)\n",
    "    ])\n",
    "\n",
    "    # Разделение данных\n",
    "    X_train = data[:n_train]\n",
    "    X_test = data[n_train:]\n",
    "\n",
    "    # Обучение и CV\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        ml_stack_pipe.fit(X_tr, y_tr)\n",
    "        preds = ml_stack_pipe.predict(X_val)\n",
    "        \n",
    "        # RMSLE\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "        scores.append(rmse)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# === Запуск Optuna ===\n",
    "study = optuna.create_study(\n",
    "    study_name=\"HousePrices_Stacking_Optuna\",\n",
    "    direction=\"minimize\",  # минимизируем RMSLE\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=)  # можно увеличить до 100+\n",
    "\n",
    "# === Вывод лучших параметров ===\n",
    "print(\"=== Лучшие параметры ===\")\n",
    "print(study.best_params)\n",
    "print(f\"Лучшее значение RMSLE: {study.best_value:.4f}\")\n",
    "\n",
    "# === Использование лучших параметров ===\n",
    "best_params = study.best_params\n",
    "\n",
    "# Настройка моделей\n",
    "cat_best = CatBoostRegressor(\n",
    "    iterations=best_params['cat_iterations'],\n",
    "    learning_rate=best_params['cat_learning_rate'],\n",
    "    depth=best_params['cat_depth'],\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_best = LGBMRegressor(\n",
    "    n_estimators=best_params['lgbm_n_estimators'],\n",
    "    max_depth=best_params['lgbm_max_depth'],\n",
    "    learning_rate=best_params['lgbm_learning_rate'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=best_params['rf_n_estimators'],\n",
    "    max_depth=best_params['rf_max_depth'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "meta_model = Ridge(alpha=best_params['ridge_alpha'])\n",
    "\n",
    "# Стекинг с лучшими параметрами\n",
    "base_models = [('catboost', cat_best), ('lgbm', lgbm_best), ('rf', rf_best)]\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "# Пайплайн\n",
    "ml_stack_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stack', stacking_regressor)\n",
    "])\n",
    "\n",
    "# Обучение на всей тренировочной выборке\n",
    "X_train = data[:n_train]\n",
    "X_test = data[n_train:]\n",
    "ml_stack_pipe.fit(X_train, y)\n",
    "\n",
    "# Предсказания\n",
    "preds = ml_stack_pipe.predict(X_test)\n",
    "preds = np.expm1(preds)  # обратное преобразование от log\n",
    "\n",
    "# === Сабмит ===\n",
    "submission = pd.DataFrame({'Id': test_id, 'SalePrice': preds})\n",
    "submission.to_csv('submission_optuna_stacking.csv', index=False)\n",
    "print(\"✅ Submission saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6efd67a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/opt/miniconda3/lib/python3.13/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /opt/miniconda3/lib/python3.13/site-packages/lightgbm/lib/lib_lightgbm.dylib\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/miniconda3/lib/python3.13/lib-dynload/../../libomp.dylib' (no such file), '/opt/miniconda3/bin/../lib/libomp.dylib' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ridge\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m     10\u001b[39m preprocessor = ColumnTransformer(\n\u001b[32m     11\u001b[39m     [\n\u001b[32m     12\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mohe_hot_coder\u001b[39m\u001b[33m'\u001b[39m, OneHotEncoder(sparse_output=\u001b[38;5;28;01mFalse\u001b[39;00m), one_hot_coder),\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     remainder = \u001b[33m'\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# .basic is intentionally loaded as early as possible, to dlopen() lib_lightgbm.{dll,dylib,so}\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# and its dependencies as early as possible\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CVBooster, cv, train\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/basic.py:9\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"Wrapper for C API of LightGBM.\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# This import causes lib_lightgbm.{dll,dylib,so} to be loaded.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# It's intentionally done here, as early as possible, to avoid issues like\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# \"libgomp.so.1: cannot allocate memory in static TLS block\" on aarch64 Linux.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# For details, see the \"cannot allocate memory in static TLS block\" entry in docs/FAQ.rst.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB  \u001b[38;5;66;03m# isort: skip\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mabc\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mctypes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/libpath.py:49\u001b[39m\n\u001b[32m     47\u001b[39m     _LIB = Mock(ctypes.CDLL)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     _LIB = \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcdll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_find_lib_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/ctypes/__init__.py:471\u001b[39m, in \u001b[36mLibraryLoader.LoadLibrary\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/ctypes/__init__.py:390\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28mself\u001b[39m._FuncPtr = _FuncPtr\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = handle\n",
      "\u001b[31mOSError\u001b[39m: dlopen(/opt/miniconda3/lib/python3.13/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /opt/miniconda3/lib/python3.13/site-packages/lightgbm/lib/lib_lightgbm.dylib\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/miniconda3/lib/python3.13/lib-dynload/../../libomp.dylib' (no such file), '/opt/miniconda3/bin/../lib/libomp.dylib' (no such file)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('ohe_hot_coder', OneHotEncoder(sparse_output=False), one_hot_coder),\n",
    "        ('target_coder', TargetEncoder(), target_coder),\n",
    "        \n",
    "    ],\n",
    "    verbose_feature_names_out = False,\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "base_models = [\n",
    "    ('catboost', CatBoostRegressor(iterations=300, verbose=0, random_state=42)),\n",
    "    ('lgbm', LGBMRegressor(n_estimators=300, random_state=42)),\n",
    "    ('rf', RandomForestRegressor(n_estimators=300, random_state=42))]\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,                # кросс-валидация для генерации OOF-предсказаний\n",
    "    n_jobs=-1,\n",
    "    passthrough=False    # если True — добавит исходные признаки к предсказаниям базовых моделей\n",
    ")\n",
    "\n",
    "ml_stack_pipe = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('stack', stacking_regressor)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7432f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder  # pip install category_encoders\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Подготовка данных (пример) ---\n",
    "# Предположим, у вас есть X_train, y_train\n",
    "# one_hot_coder = [...]  # список категориальных столбцов для OHE\n",
    "# target_coder = [...]   # список категориальных столбцов для TargetEncoder\n",
    "\n",
    "\n",
    "# --- 2. Функция для расчёта RMSLE (как в соревновании House Prices) ---\n",
    "def rmsle_score(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_score, greater_is_better=False)\n",
    "\n",
    "# Note: make_scorer инвертирует знак, поэтому в Optuna будем минимизировать (-mean_cv_score)\n",
    "\n",
    "\n",
    "# --- 3. Целевая функция для Optuna ---\n",
    "def objective(trial):\n",
    "    # --- Подбираем гиперпараметры для базовых моделей ---\n",
    "    catboost_params = {\n",
    "        'iterations': trial.suggest_int('catboost_iterations', 100, 500),\n",
    "        'learning_rate': trial.suggest_float('catboost_lr', 0.01, 0.3, log=True),\n",
    "        'depth': trial.suggest_int('catboost_depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('catboost_l2', 1e-2, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float('catboost_random_strength', 1e-2, 1.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('catboost_bagging_temp', 0.0, 1.0),\n",
    "        'verbose': 0,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    lgbm_params = {\n",
    "        'n_estimators': trial.suggest_int('lgbm_n_estimators', 100, 500),\n",
    "        'learning_rate': trial.suggest_float('lgbm_lr', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('lgbm_max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('lgbm_num_leaves', 8, 64),\n",
    "        'subsample': trial.suggest_float('lgbm_subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('lgbm_colsample', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('lgbm_reg_alpha', 1e-4, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('lgbm_reg_lambda', 1e-4, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 3, None),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_float('rf_max_features', 0.1, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    # --- Гиперпараметры мета‑модели (Ridge) ---\n",
    "    ridge_alpha = trial.suggest_float('ridge_alpha', 1e-4, 10.0, log=True)\n",
    "\n",
    "    # --- Настройки пайплайна (опционально) ---\n",
    "    # Можно также подбирать, например, sparse_output для OHE, но обычно фиксируют\n",
    "    ohe_sparse = trial.suggest_categorical('ohe_sparse', [False])\n",
    "\n",
    "    # --- Собираем пайплайн с текущими параметрами ---\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            ('ohe_hot_coder', OneHotEncoder(sparse_output=ohe_sparse), one_hot_coder),\n",
    "            ('target_coder', TargetEncoder(), target_coder),\n",
    "        ],\n",
    "        verbose_feature_names_out=False,\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    base_models = [\n",
    "        ('catboost', CatBoostRegressor(**catboost_params)),\n",
    "        ('lgbm', LGBMRegressor(**lgbm_params)),\n",
    "        ('rf', RandomForestRegressor(**rf_params))\n",
    "    ]\n",
    "    meta_model = Ridge(alpha=ridge_alpha)\n",
    "\n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=meta_model,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    )\n",
    "\n",
    "    ml_stack_pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('stack', stacking_regressor)\n",
    "    ])\n",
    "\n",
    "    # --- Кросс‑валидация на train данных ---\n",
    "    cv_scores = cross_val_score(ml_stack_pipe, X_train, y_train, cv=5, scoring=rmsle_scorer)\n",
    "    mean_cv_score = -np.mean(cv_scores)  # инвертируем знак (Optuna минимизирует)\n",
    "\n",
    "    return mean_cv_score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
